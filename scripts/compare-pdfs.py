#!/usr/bin/env python3
"""
PDF ì‹œê° ë¹„êµ ìŠ¤í¬ë¦½íŠ¸

í•œ/ê¸€ ë ˆí¼ëŸ°ìŠ¤ PDF vs HanDoc PDFë¥¼ í˜ì´ì§€ë³„ë¡œ ë¹„êµ
SSIM (Structural Similarity Index) ê¸°ë°˜ ìœ ì‚¬ë„ ì¸¡ì •

ì‚¬ìš©ë²•:
  pip install pymupdf Pillow scikit-image numpy
  python compare-pdfs.py --reference ./reference-pdfs --handoc ./handoc-pdfs --output ./comparison-report

ì¶œë ¥:
  - comparison-report.json (íŒŒì¼ë³„ ì ìˆ˜)
  - comparison-report.md (ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” ë¦¬í¬íŠ¸)
  - diffs/ (ì°¨ì´ê°€ í° íŒŒì¼ì˜ ì‹œê°ì  diff ì´ë¯¸ì§€)
"""

import argparse
import json
import os
import sys
from pathlib import Path
from datetime import datetime

try:
    import fitz  # PyMuPDF
    import numpy as np
    from PIL import Image
    from skimage.metrics import structural_similarity as ssim
except ImportError:
    print("í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í•„ìš”:")
    print("  pip install pymupdf Pillow scikit-image numpy")
    sys.exit(1)


def pdf_to_images(pdf_path: Path, dpi: int = 150) -> list[np.ndarray]:
    """PDFë¥¼ í˜ì´ì§€ë³„ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
    doc = fitz.open(str(pdf_path))
    images = []
    for page in doc:
        mat = fitz.Matrix(dpi / 72, dpi / 72)
        pix = page.get_pixmap(matrix=mat)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        images.append(np.array(img))
    doc.close()
    return images


def compare_pages(ref_img: np.ndarray, test_img: np.ndarray) -> dict:
    """ë‘ í˜ì´ì§€ ì´ë¯¸ì§€ ë¹„êµ"""
    # í¬ê¸° ë§ì¶”ê¸° (ë” ì‘ì€ ìª½ì— ë§ì¶¤)
    h = min(ref_img.shape[0], test_img.shape[0])
    w = min(ref_img.shape[1], test_img.shape[1])
    ref_crop = ref_img[:h, :w]
    test_crop = test_img[:h, :w]

    # Grayscaleë¡œ ë³€í™˜
    ref_gray = np.mean(ref_crop, axis=2).astype(np.uint8)
    test_gray = np.mean(test_crop, axis=2).astype(np.uint8)

    # SSIM ê³„ì‚°
    score, diff = ssim(ref_gray, test_gray, full=True)

    # í¬ê¸° ì°¨ì´ ë¹„ìœ¨
    size_diff = abs(ref_img.shape[0] * ref_img.shape[1] - test_img.shape[0] * test_img.shape[1])
    size_ratio = min(ref_img.shape[0] * ref_img.shape[1], test_img.shape[0] * test_img.shape[1])
    size_match = 1.0 - (size_diff / max(size_ratio, 1))

    return {
        "ssim": round(float(score), 4),
        "size_match": round(float(size_match), 4),
        "ref_size": [ref_img.shape[1], ref_img.shape[0]],
        "test_size": [test_img.shape[1], test_img.shape[0]],
        "diff": diff
    }


def compare_pdfs(ref_path: Path, test_path: Path, diff_dir: Path = None) -> dict:
    """ë‘ PDF íŒŒì¼ ë¹„êµ"""
    result = {
        "reference": str(ref_path),
        "test": str(test_path),
        "status": "unknown",
        "pages": [],
        "avg_ssim": 0,
        "min_ssim": 1.0,
        "grade": "F"
    }

    try:
        ref_images = pdf_to_images(ref_path)
        test_images = pdf_to_images(test_path)

        result["ref_pages"] = len(ref_images)
        result["test_pages"] = len(test_images)

        if len(ref_images) == 0:
            result["status"] = "ref_empty"
            return result

        if len(test_images) == 0:
            result["status"] = "test_empty"
            return result

        # í˜ì´ì§€ ìˆ˜ ì°¨ì´
        max_pages = max(len(ref_images), len(test_images))
        min_pages = min(len(ref_images), len(test_images))

        for i in range(min_pages):
            page_result = compare_pages(ref_images[i], test_images[i])
            result["pages"].append({
                "page": i + 1,
                "ssim": page_result["ssim"],
                "size_match": page_result["size_match"]
            })

            # ì°¨ì´ê°€ í° í˜ì´ì§€ diff ì´ë¯¸ì§€ ì €ì¥
            if diff_dir and page_result["ssim"] < 0.8:
                diff_path = diff_dir / f"{ref_path.stem}_page{i+1}_diff.png"
                diff_path.parent.mkdir(parents=True, exist_ok=True)
                diff_img = Image.fromarray((page_result["diff"] * 255).astype(np.uint8))
                diff_img.save(str(diff_path))

        # ëˆ„ë½ëœ í˜ì´ì§€ ì²˜ë¦¬
        for i in range(min_pages, max_pages):
            result["pages"].append({
                "page": i + 1,
                "ssim": 0.0,
                "size_match": 0.0,
                "note": "missing_in_" + ("test" if i >= len(test_images) else "reference")
            })

        # í‰ê· /ìµœì†Œ SSIM (ëˆ„ë½ í˜ì´ì§€ ì œì™¸í•˜ê³  ê³„ì‚°, í˜ì´ì§€ ìˆ˜ ì°¨ì´ í˜ë„í‹° ë³„ë„ ì ìš©)
        matched_scores = [p["ssim"] for p in result["pages"] if p.get("note") is None]
        all_scores = [p["ssim"] for p in result["pages"]]
        if matched_scores:
            matched_avg = sum(matched_scores) / len(matched_scores)
            # í˜ì´ì§€ ë§¤ì¹­ë¥  í˜ë„í‹°: ëˆ„ë½ ë¹„ìœ¨ë§Œí¼ ê°ì  (ìµœëŒ€ 30% ê°ì )
            page_match_ratio = len(matched_scores) / len(all_scores) if all_scores else 1
            penalty = min(0.30, (1 - page_match_ratio) * 0.3)
            result["avg_ssim"] = round(matched_avg - penalty, 4)
        else:
            result["avg_ssim"] = 0
        result["min_ssim"] = round(min(all_scores), 4) if all_scores else 0

        # ë“±ê¸‰
        avg = result["avg_ssim"]
        if avg >= 0.95:
            result["grade"] = "A"  # ê±°ì˜ ë™ì¼
        elif avg >= 0.85:
            result["grade"] = "B"  # ì•½ê°„ ì°¨ì´
        elif avg >= 0.70:
            result["grade"] = "C"  # ëˆˆì— ë„ëŠ” ì°¨ì´
        elif avg >= 0.50:
            result["grade"] = "D"  # ì‹¬ê°í•œ ì°¨ì´
        else:
            result["grade"] = "F"  # ì™„ì „íˆ ë‹¤ë¦„

        result["status"] = "compared"

    except Exception as e:
        result["status"] = "error"
        result["error"] = str(e)

    return result


def generate_report(results: list[dict], output_dir: Path):
    """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
    grades = {"A": 0, "B": 0, "C": 0, "D": 0, "F": 0}
    for r in results:
        grades[r.get("grade", "F")] += 1

    total = len(results)
    pass_rate = (grades["A"] + grades["B"]) / total * 100 if total else 0

    lines = [
        "# HanDoc ì‹œê° í’ˆì§ˆ ë¦¬í¬íŠ¸",
        f"",
        f"*Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}*",
        f"",
        f"## ìš”ì•½",
        f"",
        f"| í•­ëª© | ê°’ |",
        f"|------|-----|",
        f"| ì´ ë¬¸ì„œ | {total} |",
        f"| í†µê³¼ (A+B) | {grades['A'] + grades['B']} ({pass_rate:.1f}%) |",
        f"| A (â‰¥95%) | {grades['A']} |",
        f"| B (â‰¥85%) | {grades['B']} |",
        f"| C (â‰¥70%) | {grades['C']} |",
        f"| D (â‰¥50%) | {grades['D']} |",
        f"| F (<50%) | {grades['F']} |",
        f"",
        f"## ë“±ê¸‰ ê¸°ì¤€",
        f"- **A**: SSIM â‰¥ 0.95 â€” ì•„ë˜í•œê¸€ê³¼ ê±°ì˜ ë™ì¼",
        f"- **B**: SSIM â‰¥ 0.85 â€” ì•½ê°„ì˜ ì°¨ì´ (í°íŠ¸, ê°„ê²© ë“±)",
        f"- **C**: SSIM â‰¥ 0.70 â€” ëˆˆì— ë„ëŠ” ì°¨ì´",
        f"- **D**: SSIM â‰¥ 0.50 â€” ì‹¬ê°í•œ ë ˆì´ì•„ì›ƒ ì°¨ì´",
        f"- **F**: SSIM < 0.50 â€” ì™„ì „íˆ ë‹¤ë¦„ / ë¹ˆ ì¶œë ¥",
        f"",
    ]

    # ë¬¸ì œ íŒŒì¼ ëª©ë¡ (C ì´í•˜)
    problems = [r for r in results if r.get("grade", "F") in ("C", "D", "F")]
    if problems:
        lines.append("## âš ï¸ ë¬¸ì œ íŒŒì¼")
        lines.append("")
        lines.append("| íŒŒì¼ | ë“±ê¸‰ | SSIM | í˜ì´ì§€ | ë¹„ê³  |")
        lines.append("|------|------|------|--------|------|")
        for r in sorted(problems, key=lambda x: x.get("avg_ssim", 0)):
            name = Path(r.get("reference", "?")).stem[:40]
            grade = r.get("grade", "?")
            avg = r.get("avg_ssim", 0)
            pages = f"{r.get('ref_pages', '?')}/{r.get('test_pages', '?')}"
            error = r.get("error", "")[:30] if r.get("status") == "error" else ""
            lines.append(f"| {name} | {grade} | {avg:.2f} | {pages} | {error} |")
        lines.append("")

    # ì „ì²´ ê²°ê³¼ (ê°„ëµ)
    lines.append("## ì „ì²´ ê²°ê³¼")
    lines.append("")
    lines.append("| íŒŒì¼ | ë“±ê¸‰ | SSIM |")
    lines.append("|------|------|------|")
    for r in sorted(results, key=lambda x: x.get("avg_ssim", 0)):
        name = Path(r.get("reference", "?")).stem[:50]
        lines.append(f"| {name} | {r.get('grade', '?')} | {r.get('avg_ssim', 0):.2f} |")

    report_path = output_dir / "VISUAL-QUALITY-REPORT.md"
    report_path.write_text("\n".join(lines), encoding="utf-8")
    print(f"ğŸ“ ë¦¬í¬íŠ¸: {report_path}")


def main():
    parser = argparse.ArgumentParser(description="PDF ì‹œê° ë¹„êµ")
    parser.add_argument("--reference", default=None, help="í•œ/ê¸€ ë ˆí¼ëŸ°ìŠ¤ PDF ë””ë ‰í† ë¦¬ (ê¸°ë³¸: ../handoc-fixtures/pdf-hancom-win)")
    parser.add_argument("--handoc", default=None, help="HanDoc PDF ë””ë ‰í† ë¦¬ (ê¸°ë³¸: ../handoc-fixtures/pdf-001)")
    parser.add_argument("--output", default="./comparison", help="ê²°ê³¼ ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--dpi", type=int, default=150, help="ë¹„êµ DPI")
    parser.add_argument("--limit", type=int, help="ë¹„êµí•  ìµœëŒ€ íŒŒì¼ ìˆ˜")
    args = parser.parse_args()

    script_dir = Path(__file__).parent
    fixtures_dir = script_dir.parent.parent / "handoc-fixtures"
    ref_dir = Path(args.reference) if args.reference else fixtures_dir / "pdf-hancom"
    test_dir = Path(args.handoc) if args.handoc else fixtures_dir / "pdf-001"
    out_dir = Path(args.output)
    diff_dir = out_dir / "diffs"
    out_dir.mkdir(parents=True, exist_ok=True)

    # ë ˆí¼ëŸ°ìŠ¤ PDF ì°¾ê¸°
    ref_pdfs = sorted(ref_dir.rglob("*.pdf"))
    if args.limit:
        ref_pdfs = ref_pdfs[:args.limit]

    print(f"ğŸ” ë ˆí¼ëŸ°ìŠ¤ PDF: {len(ref_pdfs)}ê°œ")
    print(f"ğŸ“ HanDoc PDF: {test_dir}")
    print()

    results = []
    for i, ref_pdf in enumerate(ref_pdfs):
        rel = ref_pdf.relative_to(ref_dir)
        test_pdf = test_dir / rel

        if not test_pdf.exists():
            results.append({
                "reference": str(rel),
                "status": "missing",
                "grade": "F",
                "avg_ssim": 0
            })
            print(f"[{i+1}/{len(ref_pdfs)}] âŒ {rel.stem} â€” HanDoc PDF ì—†ìŒ")
            continue

        r = compare_pdfs(ref_pdf, test_pdf, diff_dir)
        r["reference"] = str(rel)
        results.append(r)

        icon = {"A": "ğŸŸ¢", "B": "ğŸ”µ", "C": "ğŸŸ¡", "D": "ğŸŸ ", "F": "ğŸ”´"}.get(r["grade"], "âšª")
        print(f"[{i+1}/{len(ref_pdfs)}] {icon} {rel.stem} â€” {r['grade']} (SSIM: {r['avg_ssim']:.2f})")

    # JSON ê²°ê³¼ ì €ì¥
    summary = {
        "generated": datetime.now().isoformat(),
        "dpi": args.dpi,
        "total": len(results),
        "grades": {g: sum(1 for r in results if r.get("grade") == g) for g in "ABCDF"},
        "results": results
    }
    json_path = out_dir / "comparison-results.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)

    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸
    generate_report(results, out_dir)

    print()
    print(f"{'='*60}")
    grades = summary["grades"]
    print(f"ğŸ“Š ê²°ê³¼: A={grades['A']} B={grades['B']} C={grades['C']} D={grades['D']} F={grades['F']}")
    print(f"âœ… í†µê³¼ìœ¨: {(grades['A']+grades['B'])/len(results)*100:.1f}%" if results else "")
    print(f"ğŸ“ ì¶œë ¥: {out_dir}")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
